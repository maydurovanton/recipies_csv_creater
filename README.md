# recipies_csv_creater
# Скрейпер рецептов

Набор скриптов — собираем рецепты с сайта в CSV-файл и скачиваем фотографии блюд.

## Требования

Установите зависимости:

```bash
pip install -r requirements.txt
````

Для автоматического перевода с помощью DeepL задайте переменную окружения
`DEEPL_API_KEY`.

Если целевой сайт отвечает ошибкой **403 Forbidden**, скрейпер отправляет
запросы с заголовком «как у браузера» и делает повторные попытки. Поведение
можно изменить в файле `scrape_recipes.py`, поправив настройки объекта
`session`.

## Запуск

### Сбор рецептов

```bash
python scrape_recipes.py <START_URL> [OUTPUT_DIR]
```

* `START_URL` — стартовая страница для обхода (обязательный аргумент).
* `OUTPUT_DIR` — каталог, куда складывать результаты (по умолчанию `output`).

Скрипт проходит по ссылкам, собирает данные и создаёт:

* `recipes.csv` — таблица с основной информацией;
* `text/<slug>_photos.txt` — ссылки на фотографии;
* `text/<slug>_ingredients.txt` — ингредиенты;
* `text/<slug>_steps.txt` — пошаговое описание.

### Скачивание изображений

```bash
python download_images.py <TXT_DIR> [IMAGES_DIR]
```

* `TXT_DIR` — папка с файлами `*_photos.txt` (по умолчанию `text`);
* `IMAGES_DIR` — куда сохранять картинки (по умолчанию `images`).

Скрипт читает ссылки из `*_photos.txt` и скачивает все изображения в
`IMAGES_DIR`.

```
```
